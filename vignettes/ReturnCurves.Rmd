---
title: "Return Curves Estimation"
author: "Lídia André, Callum Murphy-Barltrop, Jennifer Wadsworth"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    toc: true
    number_sections: true
    fig_width: 6 
    fig_height: 4 
vignette: >
  %\VignetteIndexEntry{ReturnCurves}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction

this is to explain what the package is able to do

```{r package, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
library(ReturnCurves)
```

```{r packneeded, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
library(cowplot)
```

## Data used

need to change this data

```{r data, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
set.seed(321)
data <- cbind(rnorm(1000), rnorm(1000))
```

# Marginal transformation

The estimation of the Angular Dependence Function and/or of the Return Curve is implemented for a bivariate vector $(X,Y)$ marginally distributed as a standard exponential distribution, i.e, $X, \, Y\sim \text{Exp}(1).$ Thus, the original data needs to be marginally transformed, which is achieved via the Probability Integral Transform. We follow the procedure of Coles and Tawn (1991) *(need to insert the references correctly)* where the empirical cumulative distribution function $\tilde{F}$ is fitted below a threshold $u$, and a Generalised Pareto Distribution (GPD) is fitted above, as follows:
\begin{equation} \label{eq:pit}
 \hat{F}(z) = \begin{cases} 
  1-\left(1-\tilde{F}(u)\right)\left[1+\xi\frac{z-u}{\sigma}\right]_+^{-1/\xi}, & \text{if } z>u, \\
  \tilde{F}(z), & \text{if } z \leq u,
  \end{cases}
\end{equation}
where $\sigma$ and $\xi$ are the scale and shape parameters of the GPD.

This is done with the function `margtrasnf` which takes a matrix containing the original data, a vector of the marginal quantiles used to fit the GPD and a boolean value `constrainedshape` which decides whether $\xi> -1$ if set to `TRUE` (Default), or $\xi \in \mathbb{R}$ if set to `FALSE` as inputs. 

Function `margtransf` returns an object of S4 class `margtrasnf.class` with six attributes:

* `data`: matrix with the data on the original margins
* `qmarg`: vector of marginal quantiles used to fit the GPD
* `constrainedshape`: whether $\xi>-1$ or $\xi\in\mathbb{R}$
* `parameters`: matrix containing parameters $(\sigma, \xi)$
* `thresh`: vector containing threshold $u$ above which the GPD is fitted 
* `dataexp`: matrix with the data on standard exponential margins

```{r margdata, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
# qmarg and constrainedshape set to the default values
expdata <- margtransf(data = data, qmarg = rep(0.95, 2), constrainedshape = T)

# attributes of the S4 object
str(expdata)

# head of the data on standard exponential margins
head(expdata@dataexp)
```

It is possible to plot an S4 object of `margtrasnf.class` with `plot`. By setting argument `which = "hist"`, histograms of each variable on original and standard exponential margins can be seen:

```{r plotsmarghist, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align = 'center'}
plot(expdata, which = "hist")
```

To visualise the time series of each variable on original and standard exponential margins, we need to set `which = "ts"`:

```{r plotsmargts, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align = 'center'}
plot(expdata, which = "ts")
```

The joint distribution on original and standard exponential margins can be access with `which = "joint"`:

```{r plotsmargjoint, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align = 'center', fig.height = 2}
plot(expdata, which = "joint")
```

Finally, it is possible to plot all these together by setting `which = "all"`, which is the default for this argument.

```{r plotsmargall, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align = 'center', fig.height = 8}
plot(expdata, which = "all") # or just plot(expdata)
```

# Estimation of the Angular dependence function

In bivariate extremes, interest lies in studying regions where both variables are extreme (asymptotic dependence) and/or where only one is extreme (asymptotic independence). A few methods, such as the one introduced by Wadsworth and Tawn (2013), aim at characterising the joint tail behaviour are available in the literature. Given standard exponentially distributed  variables $X$ and $Y$ and a slowly varying function $\mathcal{L}(\cdot; \omega)$ at $\infty,$ the joint tail behaviour of $(X,Y)$ is captured through $\lambda(\omega)$ as
\begin{equation*}
  \text{Pr}(X > \omega u,\, Y > (1-\omega) u) = \mathcal{L}(e^u; \omega)e^{-\lambda(\omega)u} \quad \text{as } u \to \infty,
\end{equation*}
which can be rewritten as
\begin{equation}\label{eq:wt}
  \text{Pr}\left(\min\left\{\frac{X}{\omega}, \, \frac{Y}{1-\omega}\right\}\right) = \mathcal{L}(e^u; \omega)e^{-\lambda(\omega)u} \quad \text{as } u \to \infty,
\end{equation}
where $\omega\in[0,1]$ and $\lambda(\omega)\geq \max\{\omega, 1-\omega\}$ is called the angular dependence function (ADF). In the case of asymptotic dependence, $\lambda(\omega)=\max\{\omega, 1-\omega\}, \, \forall\omega\in[0,1].$

Lastly, defining a min-projection variable at $\omega,$ $T_\omega = \min\left\{\frac{X}{\omega}, \, \frac{Y}{1-\omega}\right\},$ equation \eqref{eq:wt} implies that
\begin{equation}\label{eq:minproj}
  \text{Pr}(T_\omega>u+t\mid T_\omega>u) = \frac{\mathcal{L}(e^{u+t}; \omega)}{\mathcal{L}(e^u; \omega)}e^{-\lambda(\omega)t} \to e^{-\lambda(\omega)t}  \quad \text{as } u \to \infty,
\end{equation}
for any $\omega\in[0,1]$ and $t>0.$ In addition, for all $\omega\in[0,1]$ and, as $u_\omega\to \infty,$ $T_\omega^1 := (T_\omega-u_\omega\mid T_\omega>u_\omega)\sim \text{Exp}(\lambda(\omega)).$ Estimation of the ADF can be done in different ways; Murphy-Barltrop et al. (2024) present a few.

For the `ReturnCurves` package, two approaches are implemented: a pointwise estimator using the Hill estimator (Hill 1975), $\hat{\lambda}_H,$ and a smoother estimator based on Bernstein-Bézier polynomials estimated via composite likelihood methods, $\hat{\lambda}_{CL}.$ For the latter, Murphy-Barltrop et al. (2024) propose using a family of Bernstein-Bézier polynomials to improve the estimation of the ADF; given $k\in \mathbb{N}$
\begin{align}\label{eq:bbp}
  \mathcal{B}_k^*=\left\{(1-\omega)^k+\sum_{i = 1}^{k-1}\beta_i {k \choose i} \omega^i(1-\omega)^{k-i}+\omega^k=:f(\omega)\mid \omega\in[0,1],\right. \nonumber \\
  \left.\phantom{\sum_{i = 1}^{k-1}{k \choose i}}\boldsymbol{\beta}\in[0, \infty)^{k-1} \text{ such that } f(\omega)\geq\max\{\omega, 1-\omega\}\right\}.
\end{align}

As $T_\omega^1$ is exponentially distributed when $u_\omega\to\infty,$ $\boldsymbol{\beta}$ can be estimated using a composite likelihood function defined as
\begin{equation}
  \mathcal{L}_C(\boldsymbol{\beta}) = \left[\prod_{\omega \in \Omega}\lambda(\omega;\boldsymbol{\beta})^{\mid \boldsymbol{t}_\omega^1\mid}\right]\exp\left\{-\sum_{\omega \in \Omega}\sum_{t_\omega^1\in \boldsymbol{t}_\omega^1}\lambda(\omega;\boldsymbol{\beta})t_\omega\right\},
\end{equation}
where $\mid \boldsymbol{t}_\omega^1\mid$ represents the cardinality of set $\boldsymbol{t}_\omega^1:=\{t_\omega-u_\omega\mid t_\omega\in \boldsymbol{t}_\omega, \, t_\omega>u_\omega\}$ and $\Omega$ is a finit subset spanning the interval $[0,1].$ The estimator of the ADF through composite likelihood methods is given by $\lambda(\cdot;\boldsymbol{\hat\beta}_{CL})$ where $\boldsymbol{\hat\beta}_{CL}$ is the maximum likelihood estimator of $\boldsymbol{\beta}.$

Finally, Murphy-Barltrop et al. (2024) showed that incorporating knowledge of the conditional extremes (Heffernan and Tawn 2004) parameters $\alpha_{y\mid x}$ and $\alpha_{x\mid y}$ improves the estimation of the ADF. In particular, the authors show that, in order to satisfy theoretical properties of $\lambda(\omega),$ for all $\omega\in[0, \alpha_{x\mid y}^1]\cup[\alpha_{y\mid x}^1, 1]$ with $\alpha_{x\mid y}^1=\alpha_{x\mid y}/(1 + \alpha_{x\mid y})$ and $\alpha_{y\mid x}^1=1/(1 + \alpha_{y\mid x}),$ $\lambda(\omega)=\max\{\omega, 1-\omega\}.$ Thus, after estimating $\alpha_{y\mid x}$ and $\alpha_{x\mid y}$ through maximum likelihood estimation, we can set $\lambda(\omega)=\max\{\omega, 1-\omega\}$ for $\omega \in [0, \hat\alpha_{x\mid y}^1)\cup(\hat\alpha_{y\mid x}^1, 1].$ Then, for the Hill estimator, $\lambda(\omega)=\hat\lambda_H$ for $\omega \in \left[\hat\alpha_{x\mid y}^1, \hat\alpha_{y\mid x}^1\right].$ For the composite likelihood estimator, a rescaling of equation \eqref{eq:bbp} is needed to ensure continuity at $\hat\alpha_{x\mid y}^1$ and $\hat\alpha_{y\mid x}^1,$ as defined below:
\begin{align*}
  \mathcal{B}_k^1=\left\{(1-\hat\alpha_{x\mid y}^1)\left(1-\frac{v-\hat\alpha_{x\mid y}^1}{\hat\alpha_{y\mid x}^1-\hat\alpha_{x\mid y}^1}\right)^k+\sum_{i = 1}^{k-1}\beta_i {k \choose i} \left(\frac{v-\hat\alpha_{x\mid y}^1}{\hat\alpha_{y\mid x}^1-\hat\alpha_{x\mid y}^1}\right)^i\left(1-\frac{v-\hat\alpha_{x\mid y}^1}{\hat\alpha_{y\mid x}^1-\hat\alpha_{x\mid y}^1}\right)^{k-i}+\right. \\
  \left.\hat\alpha_{y\mid x}^1\left(\frac{v-\hat\alpha_{x\mid y}^1}{\hat\alpha_{y\mid x}^1-\hat\alpha_{x\mid y}^1}\right)^k=:f(v)\mid v\in\left[\hat\alpha_{x\mid y}^1, \hat\alpha_{y\mid x}^1\right],\boldsymbol{\beta}\in[0, \infty)^{k-1} \text{ such that } f(v)\geq\max\{v, 1-v\}\right\}.
\end{align*}

Estimation of the ADF can be done using the function `adf_est` which takes as inputs:

* an S4 object of class `margtransf.class` representing the marginal transformation of the data, 
* a sequence of angles `w` in $[0,1],$ 
* a string `method` indicating which estimator to get, $\lambda_H$ or $\lambda_{CL},$ 
* and a boolean value `constrained` which decides whether to incorporate conditional extremes parameters $\alpha_{y\mid x}$ and $\alpha_{x\mid y}$ in the estimation. 

Additional arguments can be defined outside of the default values; these include marginal quantiles for the min-projection variable $T^1,$ marginal quantiles to fit the conditional extremes method if `constrained=T`, the polynomial degree $k,$ the convergence tolerance and the initial values for $\boldsymbol{\beta}$ for the composite maximum likelihood procedure. Finally, due to its pointwise nature, a finer grid for $\omega$ when estimating the ADF using the Hill estimator is recommended.

Function `adf_est` returns an object of S4 class `adf_est.class` with ten attributes, where the first nine are the inputs of the function and the last is a vector `adf` containing the estimates of $\lambda(\omega).$

```{r adfest, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
# Estimation using Hill estimator without conditional extremes parameters
whill <- seq(0, 1, by = 0.001)
## q and constrained are set to the default values here
lambdah <- adf_est(margdata = expdata, w = whill, method = "hill", 
                   q = 0.95, constrained = F)

# Estimation using Hill estimator with conditional extremes parameters
## q and qalphas are set to the default values
lambdah2 <- adf_est(margdata = expdata, w = whill, method = "hill", q = 0.95,
                    qalphas = rep(0.95, 2), constrained = T)

# Estimation using CL method without conditional extremes parameters
## w, q and constrained are set to the default values here
lambdacl <- adf_est(margdata = expdata, w = seq(0, 1, by = 0.01), method = "cl",
                    q = 0.95, constrained = F)

# Estimation using CL method with conditional extremes parameters
## w, q and qalphas are set to the default values
lambdacl2 <- adf_est(margdata = expdata, w = seq(0, 1, by = 0.01), method = "cl",
                     q = 0.95, qalphas = rep(0.95, 2), constrained = T)

# attributes of the S4 object
str(lambdah)

# head of the vector with adf estimates for the first estimator
head(lambdah@adf)
```

It is possible to plot an S4 object of `adf_est.class` with `plot`, where a comparison of the estimated ADF and its the lower bound $\max\{\omega, 1-\omega\}$ is shown. 

```{r plotsadfest, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align = 'center', fig.width = 8, fig.height = 6}
# plot of the estimation of the ADF based on four different estimators
## H - Hill estimator without conditional extremes parameters
## H2 - Hill estimator with conditional extremes parameters
## CL - Smooth estimator using Composite Likelihood methods without conditional extremes
## CL2 - Smooth estimator using Composite Likelihood methods with conditional extremes
plot_grid(plot(lambdah), plot(lambdah2), plot(lambdacl), plot(lambdacl2),
          nrow = 2, labels = list("H", "H2", "CL", "CL2"), label_size = 10)
```

## Goodness-of-fit of ADF

After estimation of the ADF, it is important to assess its goodness-of-fit. Noting that $T_\omega^1=(T_\omega-u_\omega\mid T_\omega>u_\omega)\sim \text{Exp}(\lambda(\omega)) \Leftrightarrow \lambda(\omega)T_\omega^1\sim \text{Exp}(1)$ as $u_\omega\to\infty,$ we can investigate whether there is agreement between model and empirical exponential quantiles, or not. This is done in the `ReturnCurves` package through QQ plots by plotting points $\left(F_E^{-1}(i/(n+1),\, T^1_{(i)}\right)$, where $F_E^{-1}$ denotes the inverse of the cumulative distribution of a standard exponential distribution and $T_{(i)}^{-1}$ is the $i$-th ordered increasing statistic, $i=1, \ldots, n$. The uncertainty of the empirical quantiles is quantified using a bootstrap approach. If temporal dependence is present in the data, a block bootstrap approach should be used (`blocksize` $>1$).

The goodness-of-fit of $\lambda(\omega)$ can be done using the function `adf_gof` which takes an S4 object of class `adf_est.class`, ray $\omega$ to be considered, the size of the blocks for the bootstrap procedure and the corresponding number of  samples, and the significance level $\alpha$ for the tolerance intervals as inputs. In turn, it returns an S4 object of class `adf_gof.class` with an extra attribute, `gof`, containing a list with the model and empirical quantiles, and the lower and upper bounds of the tolerance interval.

We note that this function is implemented to evaluate the fit at a single ray $\omega;$ therefore, we recommend repeating the procedure for a few rays to have a better representation. In addition, if the ray provided by the user was not used for the estimation of the ADF, then the closest $\omega$ in the grid is used instead.

```{r adfgof, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}

# Goodness of fit of the adf for three rays w
rays <- c(0.25, 0.5, 0.75)
## blocksize, nboot and alpha are set to the default values
gofh <- sapply(rays, adf_gof, adf = lambdah, blocksize = 1, nboot = 250, alpha = 0.05)

# attributes of the S4 object
str(gofh[[1]])

# head of the list element of attribute gof
head(gofh[[1]]@gof$model)
head(gofh[[1]]@gof$empirical)
head(gofh[[1]]@gof$lower)
head(gofh[[1]]@gof$upper)
```

As before, it is possible to plot an S4 object of `adf_gof.class` with `plot`, where the QQ-plot with the model and empirical quantiles are shown. The points should lie close to the $y=x$ and line $y=x$ should mainly liw within the $(1-\alpha)\%$ tolerance intervals for a good fit and agreement of these quantiles.

```{r plotsadfgof, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align = 'center', fig.width = 10, fig.height = 3}
plot_grid(plot(gofh[[1]]), plot(gofh[[2]]), plot(gofh[[3]]), ncol = 3, label_size = 10)
```

# Estimation of the Return Curve

Given a probability $p$ and the joint survivor function $\text{Pr}(X>x, Y>y)$ of the bivariate vector $(X,Y),$ the $p$-probability return curve is defined as 
\begin{equation}\label{eq:rc}
  \text{RC}(p):=\{(x, y) \in \mathbb{R}^2 : \text{Pr}(X>x, Y>y) = p\}.
\end{equation}
The interest lies in values of $p$ close to $0$ as these are the ones characterising rare joint exceedances events. In addition, given any point $(x,y) \in \text{RC}(p),$ event $\{X >x, Y>y\}$ is expected to happen once each return period $1/p,$ on average. This is equivalent to observing $np$ points in the region $(x, \infty)\times (y, \infty)$ in a sample size of $n$ from $(X,Y).$ 

Since probability $p$ is close to $0,$ methods that can accurately capture the behaviour of the joint tail are necessary in order to realistically extrapolate and estimate $\text{RC}(p)$ for values of $p$ outside of the observation period. Murphy-Barltrop et al. (2023) consider a couple methods to achieve this, one of which uses the ADF $\lambda(\omega)$ given in equation \eqref{eq:wt} to characterise the joint tail behaviour.

Estimation of $\text{RC}(p)$ is done with standard exponentially distributed variables; therefore, the first step is to transform the original data onto standard exponential margins using equation \eqref{eq:pit}, and then, after estimation of $\text{RC}(p),$ back transform them onto the original margins. Estimates of $\text{RC}(p)$ are obtained through estimates of $t$ and $u$ from equation \eqref{eq:minproj}, and rays $\omega.$ In particular, the value of $t>0$ can be obtained by first estimating $u$ as the $(1-p^*)$-th quantile of $T_\omega$ where $p^*>p$ is a small probability, and then ensuring that $\text{Pr}(T_\omega > t + u)=p.$ Since $u$ is estimated as the $(1-p^*)$-th quantile of $T_\omega,$ we have that $\text{Pr}(T_\omega > u) = p^*;$ thus,
\begin{equation*}
 p = \text{Pr}(T_\omega > t + u) = \text{Pr}(T_\omega > u) \text{Pr}(T_\omega > t + u \mid T_\omega > u) = p^*e^{-\hat{\lambda}(\omega)t},
\end{equation*}
which leads to $t=-\log(p/p^*)/\hat{\lambda}(\omega).$ Finally, the estimates of the return curve $\hat{\text{RC}}(p)$ can be obtained by setting $(x, y):=\left(\omega(t+u), (1-\omega)(t+u)\right).$

In the `ReturnCurves` package, estimation of the return curve is done through function `rc_est` which shares the same inputs as function `adf_est` with an additional argument `p` representing the curve survival probability. This probability value should be smaller than $1-q,$ where $q$ is the marginal quantile for the min-projection variable $T^1,$ and when applicable, smaller than $1-q_\alpha,$ where $q_\alpha$ are the marginal quantiles used in the conditional extremes method.

Function `rc_est` returns an S4 object of class `rc_est.class` with twelve attributes, where the last is a matrix `rc` containing the the estimates of the return curve on the original margins.

```{r rcest, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
n <- dim(data)[1] 
prob <- 1/n
# Estimation using Hill estimator without conditional extremes parameters
whill <- seq(0, 1, by = 0.001)
## q and constrained are set to the default values here
rch <- rc_est(margdata = expdata, w = whill, p = prob, method = "hill", 
              q = 0.95, constrained = F)

# Estimation using Hill estimator with conditional extremes parameters
## q and qalphas are set to the default values
rch2 <- rc_est(margdata = expdata, w = whill, p = prob, method = "hill", q = 0.95,
               qalphas = rep(0.95, 2), constrained = T)

# Estimation using CL method without conditional extremes parameters
## w, q and constrained are set to the default values here
rccl <- rc_est(margdata = expdata, w = seq(0, 1, by = 0.01), p = prob, method = "cl", 
               q = 0.95, constrained = F)

# Estimation using CL method with conditional extremes parameters
## w, q and qalphas are set to the default values
rccl2 <- rc_est(margdata = expdata, w = seq(0, 1, by = 0.01), p = prob, method = "cl", 
                q = 0.95, qalphas = rep(0.95, 2), constrained = T)

# attributes of the S4 object
str(rch)

# head of the vector with adf estimates for the first estimator
head(rch@rc)
```

It is possible to plot an S4 object of `rc_est.class` with `plot`, where the original data is plotted with the estimated line for the return curve $\hat{\text{RC}}(p).$ 

```{r plotsrcest, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align = 'center', fig.width = 8, fig.height = 6}
# plot of the estimation of the RC based on four different estimators
## H - Hill estimator without conditional extremes parameters
## H2 - Hill estimator with conditional extremes parameters
## CL - Smooth estimator using Composite Likelihood methods without conditional extremes
## CL2 - Smooth estimator using Composite Likelihood methods with conditional extremes
plot_grid(plot(rch), plot(rch2), plot(rccl), plot(rccl2),
          nrow = 2, labels = list("H", "H2", "CL", "CL2"), label_size = 10)
```

## Uncertainty of Return Curves

Murphy-Barltrop et al. (2023) propose a procedure to assess the uncertainty of the return curve estimates. Considering the set of angles
\begin{equation}\label{eq:angles}
  \boldsymbol{\Theta}:=\left\{\frac{\pi(m+1-j)}{2(m+1)} \mid 1 \leq j\leq m\right\},
\end{equation}
for large positive $m \in \mathbb{N},$ for each $\theta \in \boldsymbol{\Theta},$ line $L_\theta :=\{(x,y) \in \mathbb{R}^2_+ \mid \tan(\theta)>0\}$ intersects the estimated $\hat{\text{RC}}(p)$ exactly once, i.e., $\{(\hat{x}_\theta, \hat{y}_\theta)\}:= \hat{\text{RC}}(p) \cap L_\theta$ where $(\hat{x}_\theta, \hat{y}_\theta) \in \hat{\text{RC}}(p).$ Moreover, let $\hat{d}_\theta := \left(\hat{x}_\theta^2 + \hat{y}_\theta^2\right)^{1/2}$ denote the $L_2$-norm of the point estimate. 

Uncertainty in the return curve estimates is quantified using the distribution of $\hat{d}_\theta$ at each angle $\theta \in \boldsymbol{\Theta}$ as follows: for $k = 1, \ldots,$ `nboot`:
\begin{enumerate}
  \item Bootstrap the original data set; when temporal dependence is present, a block bootstrap should be used.
  \item For each $\theta \in \boldsymbol{\Theta},$ obtain $\hat{d}_{\theta,k}$ for the corresponding return curve estimate.
\end{enumerate}

Finally, given $\theta \in \boldsymbol{\Theta},$ empirical estimates of the mean, median and $(1-\alpha)\%$ confidence intervals for $\hat{d}_\theta$ can be obtained using the sample of $\hat{d}_{\theta,k}.$ These are available through function `rc_unc`, which takes as inputs:

* `retcurve`: an S4 object of class `rc_est.class` containing the return curve estimates,
* `blocksize`: size of blocks for the block bootstrap procedure; if no temporal dependence is present, then set `blocksize = 1`,
* `nboot`: number of bootstrap samples to be taken,
* `nangles`: number of angles $m$,
* `alpha`: significance level to compute the $(1-\alpha)\%$ confidence intervals.

Function `rc_unc` returns an S4 object of class `rc_unc.class` with six attributes, where the last slot `unc` contains a list with

* `median`: a vector containing the empirical estimates of the median return curve
* `mean`: a vector containing the empirical estimates of the mean return curve
* `lower`: a vector containing the lower bound of the confidence interval
* `upper`: a vector containing the upper bound of the confidence interval

## Goodness-of-fit of Return Curves

explain the methodology behind



