---
title: "Return Curves Estimation"
author: "Lídia André, Callum Murphy-Barltrop, Jennifer Wadsworth"
date: "`r Sys.Date()`"
bibliography: refvignette.bib
link-citations: true
output: 
  pdf_document:
    toc: true
    number_sections: true
    fig_width: 6 
    fig_height: 4 
    citation_package: natbib
vignette: >
  %\VignetteIndexEntry{Return Curves Estimation}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction

This vignette provides complementary information to the R Documentation
for the `ReturnCurves` package. It summarises the key methodologies
implemented in the package and is heavily based on the works of
@MurphyBarltropetal2023 and @MurphyBarltropetal2024; for full details we
refer the user to these articles.

The `ReturnCurves` package aims at estimating the $p$-probability return
curve [@MurphyBarltropetal2023], while implementing pointwise and smooth
approaches to estimate the so called angular dependence function first
introduced by [@WadsworthTawn2013].

```{r package, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
library(ReturnCurves)
```

```{r packneeded, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
library(gridExtra)
```

To illustrate the functionality of the package, we use ... data *need to
find better data yet*

```{r data, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
set.seed(321)
data <- cbind(rnorm(1000), rnorm(1000))
```

# Marginal transformation

The estimation of the Angular Dependence Function and/or of the Return
Curve is implemented for a bivariate vector $(X_E,Y_E)$ marginally
distributed as a standard exponential distribution, i.e,
$X_E, \, Y_E\sim \text{Exp}(1).$ Thus, the original data needs to be
marginally transformed, which is achieved via the Probability Integral
Transform. We follow the procedure of @ColesTawn1991 where the empirical
cumulative distribution function $\tilde{F}$ is fitted below a threshold
$u$, and a Generalised Pareto Distribution (GPD) is fitted above, as
follows: \begin{equation} \label{eq:pit}
 \hat{F}(z) = \begin{cases} 
  1-\left(1-\tilde{F}(u)\right)\left[1+\xi\frac{z-u}{\sigma}\right]_+^{-1/\xi}, & \text{if } z>u, \\
  \tilde{F}(z), & \text{if } z \leq u,
  \end{cases}
\end{equation} where $\sigma$ and $\xi$ are the scale and shape
parameters of the GPD.

This is done with the function `margtrasnf` which takes a matrix
containing the original data, a vector of the marginal quantiles used to
fit the GPD and a boolean value `constrainedshape` which decides whether
$\xi> -1$ if set to `TRUE` (Default), or $\xi \in \mathbb{R}$ if set to
`FALSE` as inputs.

Function `margtransf` returns an object of S4 class `margtrasnf.class`
with six attributes:

-   `data`: matrix with the data on the original margins
-   `qmarg`: vector of marginal quantiles used to fit the GPD
-   `constrainedshape`: whether $\xi>-1$ or $\xi\in\mathbb{R}$
-   `parameters`: matrix containing parameters $(\sigma, \xi)$
-   `thresh`: vector containing threshold $u$ above which the GPD is
    fitted
-   `dataexp`: matrix with the data on standard exponential margins

```{r margdata, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
# qmarg and constrainedshape set to the default values
expdata <- margtransf(data = data, qmarg = rep(0.95, 2), constrainedshape = T)

# attributes of the S4 object
str(expdata)

# head of the data on standard exponential margins
head(expdata@dataexp)
```

It is possible to plot an S4 object of `margtrasnf.class` with `plot`.
By setting argument `which = "hist"`, histograms of each variable on
original and standard exponential margins can be seen:

```{r plotsmarghist, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align = 'center'}
plot(expdata, which = "hist")
```

To visualise the time series of each variable on original and standard
exponential margins, we need to set `which = "ts"`:

```{r plotsmargts, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align = 'center'}
plot(expdata, which = "ts")
```

The joint distribution on original and standard exponential margins can
be access with `which = "joint"`:

```{r plotsmargjoint, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align = 'center', fig.height = 3}
plot(expdata, which = "joint")
```

Finally, it is possible to plot all these together by setting
`which = "all"`, which is the default for this argument.

```{r plotsmargall, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align = 'center', fig.height = 8}
plot(expdata, which = "all") # or just plot(expdata)
```

# Estimation of the Angular dependence function

In bivariate extremes, interest lies in studying regions where both
variables are extreme (asymptotic dependence) and/or where only one is
extreme (asymptotic independence). A few methods, such as the one
introduced by @WadsworthTawn2013, aim at characterising the joint tail
behaviour are available in the literature. Given standard exponentially
distributed variables $X_E$ and $Y_E$ and a slowly varying function
$\mathcal{L}(\cdot; \omega)$ at $\infty,$ the joint tail behaviour of
$(X_E,Y_E)$ is captured through $\lambda(\omega)$ as \begin{equation*}
  \text{Pr}(X_E > \omega u,\, Y_E > (1-\omega) u) = \mathcal{L}(e^u; \omega)e^{-\lambda(\omega)u} \quad \text{as } u \to \infty,
\end{equation*} which can be rewritten as \begin{equation}\label{eq:wt}
  \text{Pr}\left(\min\left\{\frac{X_E}{\omega}, \, \frac{Y_E}{1-\omega}\right\}\right) = \mathcal{L}(e^u; \omega)e^{-\lambda(\omega)u} \quad \text{as } u \to \infty,
\end{equation} where $\omega\in[0,1]$ and
$\lambda(\omega)\geq \max\{\omega, 1-\omega\}$ is called the angular
dependence function (ADF). In the case of asymptotic dependence,
$\lambda(\omega)=\max\{\omega, 1-\omega\}, \, \forall\omega\in[0,1].$

Lastly, defining a min-projection variable at $\omega,$
$T_\omega = \min\left\{\frac{X_E}{\omega}, \, \frac{Y_E}{1-\omega}\right\},$
equation \eqref{eq:wt} implies that \begin{equation}\label{eq:minproj}
  \text{Pr}(T_\omega>u+t\mid T_\omega>u) = \frac{\mathcal{L}(e^{u+t}; \omega)}{\mathcal{L}(e^u; \omega)}e^{-\lambda(\omega)t} \to e^{-\lambda(\omega)t}  \quad \text{as } u \to \infty,
\end{equation} for any $\omega\in[0,1]$ and $t>0.$ In addition, for all
$\omega\in[0,1]$ and, as $u_\omega\to \infty,$
$T_\omega^1 := (T_\omega-u_\omega\mid T_\omega>u_\omega)\sim \text{Exp}(\lambda(\omega)).$
Estimation of the ADF can be done in different ways;
[@MurphyBarltropetal2024] present a few.

For the `ReturnCurves` package, two approaches are implemented: a
pointwise estimator using the Hill estimator [@Hill1975],
$\hat{\lambda}_H,$ and a smoother estimator based on Bernstein-Bézier
polynomials estimated via composite likelihood methods,
$\hat{\lambda}_{CL}.$ For the latter, @MurphyBarltropetal2024 propose
using a family of Bernstein-Bézier polynomials to improve the estimation
of the ADF; given $k\in \mathbb{N}$ \begin{align}\label{eq:bbp}
  \mathcal{B}_k^*=\left\{(1-\omega)^k+\sum_{i = 1}^{k-1}\beta_i {k \choose i} \omega^i(1-\omega)^{k-i}+\omega^k=:f(\omega)\mid \omega\in[0,1],\right. \nonumber \\
  \left.\phantom{\sum_{i = 1}^{k-1}{k \choose i}}\boldsymbol{\beta}\in[0, \infty)^{k-1} \text{ such that } f(\omega)\geq\max\{\omega, 1-\omega\}\right\}.
\end{align}

As $T_\omega^1$ is exponentially distributed when $u_\omega\to\infty,$
$\boldsymbol{\beta}$ can be estimated using a composite likelihood
function defined as \begin{equation}
  \mathcal{L}_C(\boldsymbol{\beta}) = \left[\prod_{\omega \in \Omega}\lambda(\omega;\boldsymbol{\beta})^{\mid \boldsymbol{t}_\omega^1\mid}\right]\exp\left\{-\sum_{\omega \in \Omega}\sum_{t_\omega^1\in \boldsymbol{t}_\omega^1}\lambda(\omega;\boldsymbol{\beta})t_\omega\right\},
\end{equation} where $\mid \boldsymbol{t}_\omega^1\mid$ represents the
cardinality of set
$\boldsymbol{t}_\omega^1:=\{t_\omega-u_\omega\mid t_\omega\in \boldsymbol{t}_\omega, \, t_\omega>u_\omega\}$
and $\Omega$ is a finite subset spanning the interval $[0,1].$ The
estimator of the ADF through composite likelihood methods is given by
$\lambda(\cdot;\boldsymbol{\hat\beta}_{CL})$ where
$\boldsymbol{\hat\beta}_{CL}$ is the maximum likelihood estimator of
$\boldsymbol{\beta}.$

Finally, @MurphyBarltropetal2024 showed that incorporating knowledge of
the conditional extremes [@HeffernanTawn2004] parameters
$\alpha_{y\mid x}$ and $\alpha_{x\mid y}$ improves the estimation of the
ADF. In particular, the authors show that, in order to satisfy
theoretical properties of $\lambda(\omega),$ for all
$\omega\in[0, \alpha_{x\mid y}^1]\cup[\alpha_{y\mid x}^1, 1]$ with
$\alpha_{x\mid y}^1=\alpha_{x\mid y}/(1 + \alpha_{x\mid y})$ and
$\alpha_{y\mid x}^1=1/(1 + \alpha_{y\mid x}),$
$\lambda(\omega)=\max\{\omega, 1-\omega\}.$ Thus, after estimating the
conditional extremes parameters $\alpha_{y\mid x}$ and
$\alpha_{x\mid y}$ through maximum likelihood estimation, we can set
$\lambda(\omega)=\max\{\omega, 1-\omega\}$ for
$\omega \in [0, \hat\alpha_{x\mid y}^1)\cup(\hat\alpha_{y\mid x}^1, 1].$
Then, for the Hill estimator, $\lambda(\omega)=\hat\lambda_H$ for
$\omega \in \left[\hat\alpha_{x\mid y}^1, \hat\alpha_{y\mid x}^1\right].$
For the composite likelihood estimator, a rescaling of equation
\eqref{eq:bbp} is needed to ensure continuity at
$\hat\alpha_{x\mid y}^1$ and $\hat\alpha_{y\mid x}^1,$ as defined below:
\begin{align*}
  \mathcal{B}_k^1=\left\{(1-\hat\alpha_{x\mid y}^1)\left(1-\frac{v-\hat\alpha_{x\mid y}^1}{\hat\alpha_{y\mid x}^1-\hat\alpha_{x\mid y}^1}\right)^k+\sum_{i = 1}^{k-1}\beta_i {k \choose i} \left(\frac{v-\hat\alpha_{x\mid y}^1}{\hat\alpha_{y\mid x}^1-\hat\alpha_{x\mid y}^1}\right)^i\left(1-\frac{v-\hat\alpha_{x\mid y}^1}{\hat\alpha_{y\mid x}^1-\hat\alpha_{x\mid y}^1}\right)^{k-i}+\right. \\
  \left.\hat\alpha_{y\mid x}^1\left(\frac{v-\hat\alpha_{x\mid y}^1}{\hat\alpha_{y\mid x}^1-\hat\alpha_{x\mid y}^1}\right)^k=:f(v)\mid v\in\left[\hat\alpha_{x\mid y}^1, \hat\alpha_{y\mid x}^1\right],\boldsymbol{\beta}\in[0, \infty)^{k-1} \text{ such that } f(v)\geq\max\{v, 1-v\}\right\}.
\end{align*}

Estimation of the ADF can be done using the function `adf_est` which
takes as inputs:

-   an S4 object of class `margtransf.class` representing the marginal
    transformation of the data,
-   a sequence of rays `w` in $[0,1],$
-   a string `method` indicating which estimator to get, $\lambda_H$ or
    $\lambda_{CL},$
-   and a boolean value `constrained` which decides whether to
    incorporate conditional extremes parameters $\alpha_{y\mid x}$ and
    $\alpha_{x\mid y}$ in the estimation.

Additional arguments can be defined outside of the default values; these
include marginal quantiles for the min-projection variable $T^1,$
marginal quantiles to fit the conditional extremes method if
`constrained=T`, the polynomial degree $k,$ the convergence tolerance
and the initial values for $\boldsymbol{\beta}$ for the composite
maximum likelihood procedure. Finally, due to its pointwise nature, a
finer grid for $\omega$ when estimating the ADF using the Hill estimator
is recommended.

Function `adf_est` returns an object of S4 class `adf_est.class` with
ten attributes, where the first nine are the inputs of the function and
the last is a vector `adf` containing the estimates of
$\lambda(\omega).$

```{r adfest, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
# Estimation using Hill estimator without conditional extremes parameters
whill <- seq(0, 1, by = 0.001)
## q and constrained are set to the default values here
lambdah <- adf_est(margdata = expdata, w = whill, method = "hill", 
                   q = 0.95, constrained = F)

# Estimation using Hill estimator with conditional extremes parameters
## q and qalphas are set to the default values
lambdah2 <- adf_est(margdata = expdata, w = whill, method = "hill", q = 0.95,
                    qalphas = rep(0.95, 2), constrained = T)

# Estimation using CL method without conditional extremes parameters
## w, q and constrained are set to the default values here
lambdacl <- adf_est(margdata = expdata, w = seq(0, 1, by = 0.01), method = "cl",
                    q = 0.95, constrained = F)

# Estimation using CL method with conditional extremes parameters
## w, q and qalphas are set to the default values
lambdacl2 <- adf_est(margdata = expdata, w = seq(0, 1, by = 0.01), method = "cl",
                     q = 0.95, qalphas = rep(0.95, 2), constrained = T)

# attributes of the S4 object
str(lambdah)

# head of the vector with adf estimates for the first estimator
head(lambdah@adf)
```

It is possible to plot an S4 object of `adf_est.class` with `plot`,
where a comparison of the estimated ADF and its lower bound,
$\max\{\omega, 1-\omega\},$ is shown.

```{r plotsadfest, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.width = 3, fig.height = 3, fig.align = 'center'}
# plot of the ADF estimation based on the unconstrained Hill estimator
plot(lambdah)
```

## Goodness-of-fit of the angular dependence function

After estimation of the ADF, it is important to assess its
goodness-of-fit. Noting that
$T_\omega^1=(T_\omega-u_\omega\mid T_\omega>u_\omega)\sim \text{Exp}(\lambda(\omega)) \Leftrightarrow \lambda(\omega)T_\omega^1\sim \text{Exp}(1)$
as $u_\omega\to\infty,$ we can investigate whether there is agreement
between model and empirical exponential quantiles, or not. This is done
in the `ReturnCurves` package through QQ plots by plotting points
$\left(F_E^{-1}(i/(n+1),\, T^1_{(i)}\right)$, where $F_E^{-1}$ denotes
the inverse of the cumulative distribution of a standard exponential
distribution and $T_{(i)}^{-1}$ is the $i$-th ordered increasing
statistic, $i=1, \ldots, n$. The uncertainty of the empirical quantiles
is quantified using a bootstrap approach. If temporal dependence is
present in the data, a block bootstrap approach should be used
(`blocksize` $>1$).

The assessment of the goodness-of-fit of $\lambda(\omega)$ can be done
using the function `adf_gof` which takes an S4 object of class
`adf_est.class`, ray $\omega$ to be considered, the size of the blocks
for the bootstrap procedure and the corresponding number of samples, and
the significance level $\alpha$ for the tolerance intervals as inputs.
In turn, it returns an S4 object of class `adf_gof.class` with an extra
attribute, `gof`, containing a list with the model and empirical
quantiles, and the lower and upper bounds of the tolerance interval.

We note that this function is implemented to evaluate the fit at a
single ray $\omega;$ therefore, we recommend repeating the procedure for
a few rays to have a better representation. In addition, if the ray
provided by the user was not used for the estimation of the ADF, then
the closest $\omega$ in the grid is used instead.

```{r adfgof, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}

# Goodness of fit of the adf for three rays w
rays <- c(0.25, 0.5, 0.75)
## blocksize, nboot and alpha are set to the default values
gofh <- sapply(rays, adf_gof, adf = lambdah, blocksize = 1, nboot = 250, alpha = 0.05)

# attributes of the S4 object
str(gofh[[1]])

# head of the list elements of slot gof
head(gofh[[1]]@gof$model)
head(gofh[[1]]@gof$empirical)
head(gofh[[1]]@gof$lower)
head(gofh[[1]]@gof$upper)
```

As before, it is possible to plot an S4 object of `adf_gof.class` with
`plot`, where the QQ-plot with the model and empirical quantiles are
shown. The points should lie close to the line $y=x;$ for a good fit and
agreement between these quantile, line $y=x$ should mainly lie within
the $(1-\alpha)\%$ tolerance intervals.

```{r plotsadfgof, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align = 'center', fig.width = 10, fig.height = 3}
grid.arrange(plot(gofh[[1]]), plot(gofh[[2]]), plot(gofh[[3]]), ncol = 3)
```

# Estimation of the Return Curve

Given a probability $p$ and the joint survivor function
$\text{Pr}(X>x, Y>y)$ of the bivariate vector $(X,Y),$ the
$p$-probability return curve is defined as \begin{equation}\label{eq:rc}
  \text{RC}(p):=\{(x, y) \in \mathbb{R}^2 : \text{Pr}(X>x, Y>y) = p\}.
\end{equation} The interest lies in values of $p$ close to $0$ as these
are the ones characterising rare joint exceedances events. In addition,
given any point $(x,y) \in \text{RC}(p),$ event $\{X >x, Y>y\}$ is
expected to happen once each return period $1/p,$ on average. This is
equivalent to observing $np$ points in the region
$(x, \infty)\times (y, \infty)$ in a sample size of $n$ from $(X,Y).$

Since probability $p$ is close to $0,$ methods that can accurately
capture the behaviour of the joint tail are necessary in order to
realistically extrapolate and estimate $\text{RC}(p)$ for values of $p$
outside of the observation period. @MurphyBarltropetal2023 consider a
couple of methods to achieve this, one of which uses the ADF
$\lambda(\omega)$ given in equation \eqref{eq:wt} to characterise the
joint tail behaviour.

Estimation of $\text{RC}(p)$ is done with standard exponentially
distributed variables; therefore, the first step is to transform the
original data onto standard exponential margins using equation
\eqref{eq:pit}, and then, after estimation of $\text{RC}(p),$ back
transform them onto the original margins. Estimates of $\text{RC}(p)$
are obtained through estimates of $t$ and $u$ from equation
\eqref{eq:minproj}, and rays $\omega.$ In particular, the value of $t>0$
can be obtained by first estimating $u$ as the $(1-p^*)$-th quantile of
$T_\omega$ where $p^*>p$ is a small probability, and then ensuring that
$\text{Pr}(T_\omega > t + u)=p.$ Since $u$ is estimated as the
$(1-p^*)$-th quantile of $T_\omega,$ we have that
$\text{Pr}(T_\omega > u) = p^*;$ thus, \begin{equation*}
 p = \text{Pr}(T_\omega > t + u) = \text{Pr}(T_\omega > u) \text{Pr}(T_\omega > t + u \mid T_\omega > u) = p^*e^{-\hat{\lambda}(\omega)t},
\end{equation*} which leads to $t=-\log(p/p^*)/\hat{\lambda}(\omega).$
Finally, the estimates of the return curve $\hat{\text{RC}}(p)$ can be
obtained by setting $(x, y):=\left(\omega(t+u), (1-\omega)(t+u)\right).$

In the `ReturnCurves` package, estimation of the return curve is done
through function `rc_est` which shares the same inputs as function
`adf_est` with an additional argument `p` representing the curve
survival probability. This probability value should be smaller than
$1-q,$ where $q$ is the marginal quantile for the min-projection
variable $T^1,$ and, when applicable, smaller than $1-q_\alpha,$ where
$q_\alpha$ are the marginal quantiles used in the conditional extremes
method.

Function `rc_est` returns an S4 object of class `rc_est.class` with
twelve attributes, where the last slot `rc` contains a matrix with the
estimates of the return curve on the original margins.

```{r rcest, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
n <- dim(data)[1] 
prob <- 10/n
# Estimation using Hill estimator without conditional extremes parameters
whill <- seq(0, 1, by = 0.001)
## q and constrained are set to the default values here
rch <- rc_est(margdata = expdata, w = whill, p = prob, method = "hill", 
              q = 0.95, constrained = F)

# Estimation using Hill estimator with conditional extremes parameters
## q and qalphas are set to the default values
rch2 <- rc_est(margdata = expdata, w = whill, p = prob, method = "hill", q = 0.95,
               qalphas = rep(0.95, 2), constrained = T)

# Estimation using CL method without conditional extremes parameters
## w, q and constrained are set to the default values here
rccl <- rc_est(margdata = expdata, w = seq(0, 1, by = 0.01), p = prob, method = "cl", 
               q = 0.95, constrained = F)

# Estimation using CL method with conditional extremes parameters
## w, q and qalphas are set to the default values
rccl2 <- rc_est(margdata = expdata, w = seq(0, 1, by = 0.01), p = prob, method = "cl", 
                q = 0.95, qalphas = rep(0.95, 2), constrained = T)

# attributes of the S4 object
str(rch)

# head of the vector with adf estimates for the first estimator
head(rch@rc)
```

It is possible to plot an S4 object of `rc_est.class` with `plot`, where
the original data is plotted with the estimated line for the return
curve $\hat{\text{RC}}(p).$

```{r plotsrcest, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.width = 3, fig.height = 3, fig.align = 'center'}
# plot of the ADF estimation based on the unconstrained Hill estimator
plot(rch)
```

## Uncertainty of the return curve estimates

@MurphyBarltropetal2023 propose a procedure to assess the uncertainty of
the return curve estimates. For large positive $m\in\mathbb{N},$ let
\begin{equation}\label{eq:angles}
  \boldsymbol{\Theta}:=\left\{\frac{\pi(m+1-j)}{2(m+1)} \mid 1 \leq j\leq m\right\},
\end{equation} define a set of angles. For each
$\theta \in \boldsymbol{\Theta},$ line
$L_\theta :=\{(x,y) \in \mathbb{R}^2_+ \mid \tan(\theta)>0\}$ intersects
the estimated $\hat{\text{RC}}(p)$ exactly once, i.e.,
$\{(\hat{x}_\theta, \hat{y}_\theta)\}:= \hat{\text{RC}}(p) \cap L_\theta$
where $(\hat{x}_\theta, \hat{y}_\theta) \in \hat{\text{RC}}(p).$
Moreover, let
$\hat{d}_\theta := \left(\hat{x}_\theta^2 + \hat{y}_\theta^2\right)^{1/2}$
denote the $L_2$-norm of the point estimate.

Uncertainty in the return curve estimates is quantified using the
distribution of $\hat{d}_\theta$ at each angle
$\theta \in \boldsymbol{\Theta}$ as follows: for $k = 1, \ldots,$
`nboot`:

```{=tex}
\begin{enumerate}
  \item Bootstrap the original data set; when temporal dependence is present, a block bootstrap should be used.
  \item For each $\theta \in \boldsymbol{\Theta},$ obtain $\hat{d}_{\theta,k}$ for the corresponding return curve estimate.
\end{enumerate}
```
Finally, given $\theta \in \boldsymbol{\Theta},$ empirical estimates of
the mean, median and $(1-\alpha)\%$ confidence intervals for
$\hat{d}_\theta$ can be obtained using the sample of
$\hat{d}_{\theta,k}.$ These are available through function `rc_unc`,
which takes as inputs:

-   `retcurve`: an S4 object of class `rc_est.class` containing the
    return curve estimates,
-   `blocksize`: size of blocks for the block bootstrap procedure; if no
    temporal dependence is present, then set `blocksize = 1`,
-   `nboot`: number of bootstrap samples to be taken,
-   `nangles`: number of angles $m$,
-   `alpha`: significance level to compute the $(1-\alpha)\%$ confidence
    intervals.

Function `rc_unc` returns an S4 object of class `rc_unc.class` with six
attributes, where the last slot `unc` contains a list with

-   `median`: a vector containing the empirical estimates of the median
    return curve
-   `mean`: a vector containing the empirical estimates of the mean
    return curve
-   `lower`: a vector containing the lower bound of the confidence
    interval
-   `upper`: a vector containing the upper bound of the confidence
    interval

For simplicity, just the uncertainty of the return curve obtained using
the unconstrained Hill estimator is computed here.

```{r rcunc, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
# blocksize, nangles and alpha set to default
# nboot set to 100 for computational time < 5s
rch_unc <- rc_unc(rch, blocksize = 1, nboot = 100, nangles = 150, alpha = 0.05)

# attributes of the S4 object
str(rch_unc)

# head of the list elements of slot unc
head(rch_unc@unc$median)
head(rch_unc@unc$mean)
head(rch_unc@unc$lower)
head(rch_unc@unc$upper)
```

It is possible to plot an instance of the S4 class `rc_unc.class` with
function `plot`; this takes the S4 object and an extra argument `which`
as inputs. If `which = "rc"` (default), then the estimated return curve
is plotted, setting `which = "median"` shows the empirical median
estimates of the return curve, while setting `which = "mean"` shows the
empirical mean estimates of the return curve. All plots show the
uncertainty associated with the estimated return curve in dashed lines.
Finally, by setting `which = "all"`, plots the estimated return curve,
the empirical median and mean estimates and the associated uncertainty.

```{r plotsrcunc, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align = 'center', fig.height=6,fig.width=8}
grid.arrange(plot(rch_unc, which = "rc"), plot(rch_unc, which = "median"), 
             plot(rch_unc, which = "mean"), plot(rch_unc, which = "all"), nrow = 2)
```

## Goodness-of-fit of the return curve estimates

It is important to assess the goodness-of-fit of the return curve
estimates, given that the true return curve is unknown in reality. This
is implemented in the `ReturnCurves` package based on the approach
proposed by @MurphyBarltropetal2023.

Given the return curve $\text{RC}(p),$ the probability of lying in a
survival region $(x, \infty)\times(y,\infty)$ is $p.$ Given the same set
of angles $\boldsymbol{\Theta}$ as in equation \eqref{eq:angles}, for
each $\theta_j\in\boldsymbol{\Theta},$ the empirical probability
$\hat p_j$ of lying in
$(\hat{x}_{\theta_j}, \infty)\times (\hat{y}_{\theta_j}, \infty),$ where
$(\hat{x}_{\theta_j}, \hat{y}_{\theta_j})$ is the corresponding point in
$\hat{\text{RC}}(p),$ is given by the proportion of points in that
region. The goodness-of-fit of the estimated return curve is then
assessed via a bootstrap procedure; for each angle
$\theta_j\in\boldsymbol{\Theta},$ the original data set is bootstrapped
and empirical probability estimates $\hat p_j$ are obtained. When
temporal dependence is present in the data, a block bootstrap approach
should be taken and the size of the blocks must be defined. We note that
for each $j,$ `nboot` empirical probabilities are estimated and, so the
median and the $(1-\alpha)\%$ pointwise confidence intervals for the
probabilities are obtained by taking the $50\%,$ $(\alpha/2)\%$ and
$(1-\alpha/2)\%$ quantiles of the set of empirical probabilities for
each $j,$ respectively.

The goodness-of-fit for an estimated return curve is implemented through
function `rc_gof`. This shares the same input arguments as the `rc_unc`
function and returns an S4 object with six attributes with the last slot
`gof` containing a list with

-   `median`: a vector with the median of the empirical probabilities,
-   `lower`: a vector with the lower bound of the confidence interval,
-   `upper`: a vector with the upper bound of the confidence interval.

For simplicity, just the goodness-of-fit of the return curve obtained
using the unconstrained Hill estimator is computed here.

```{r rcgof, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
# blocksize, nboot, nangles and alpha set to default
rch_gof <- rc_gof(rch, blocksize = 1, nboot = 250, nangles = 150, alpha = 0.05)

# attributes of the S4 object
str(rch_gof)

# head of the list elements of slot gof
head(rch_gof@gof$median)
head(rch_gof@gof$lower)
head(rch_gof@gof$upper)
```

It is possible to plot an instance of the S4 class `rc_gof.class` with
function `plot`, where a comparison between the true probability $p$ (in
red) and the empirical median estimates (in black) is shown. Ideally,
$p$ should be contained in the confidence region, shaded in grey.
Finally, in practice, value $p$ should not be within the range of the
data and not too extreme given the nature of empirical probabilities.

```{r plotsrcgof, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align = 'center'}
plot(rch_gof)
```

# References
